{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bfb09d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Set PYTHONPATH environment variable for the kernel\n",
    "robofin_path = os.path.join(os.getcwd(), 'robofin')\n",
    "current_pythonpath = os.environ.get('PYTHONPATH', '')\n",
    "if robofin_path not in current_pythonpath:\n",
    "    os.environ['PYTHONPATH'] = f\"{robofin_path}:{current_pythonpath}\" if current_pythonpath else robofin_path\n",
    "\n",
    "# Also add to sys.path for immediate effect\n",
    "if robofin_path not in sys.path:\n",
    "    sys.path.insert(0, robofin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a73a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(obj):\n",
    "    \"\"\"\n",
    "    Function for displaying nested types.\n",
    "    \n",
    "    e.g. get_type(dict_str_float) -> \"dict[str, float]\"\n",
    "    \"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        if not obj:\n",
    "            return \"dict[?, ?]\"\n",
    "        key_types = {get_type(k) for k in obj.keys()}\n",
    "        value_types = {get_type(v) for v in obj.values()}\n",
    "        return f\"dict[{', '.join(key_types)}, {', '.join(value_types)}]\"\n",
    "    elif isinstance(obj, list):\n",
    "        if not obj:\n",
    "            return \"list[?]\"\n",
    "        elem_types = {get_type(elem) for elem in obj}\n",
    "        return f\"list[{', '.join(elem_types)}]\"\n",
    "    elif isinstance(obj, tuple):\n",
    "        if not obj:\n",
    "            return \"tuple[?]\"\n",
    "        elem_types = [get_type(elem) for elem in obj]\n",
    "        return f\"tuple[{', '.join(elem_types)}]\"\n",
    "    elif isinstance(obj, set):\n",
    "        if not obj:\n",
    "            return \"set[?]\"\n",
    "        elem_types = {get_type(elem) for elem in obj}\n",
    "        return f\"set[{', '.join(elem_types)}]\"\n",
    "    else:\n",
    "        return type(obj).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ac890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df16f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from robofin.robots import Robot\n",
    "\n",
    "# Load the Robot class with the standard URDF file (that uses relative filepaths)\n",
    "robot = Robot(\"assets/panda/panda.urdf\")\n",
    "# robot = Robot(\"assets/gp7/gp7.urdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7373bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the pxr USD Python bindings to the Python path if they exist\n",
    "usd_python_path = \"/opt/PixarAnimationStudios/USD/lib/python\"\n",
    "if os.path.isdir(usd_python_path):\n",
    "    if usd_python_path not in sys.path:\n",
    "        sys.path.insert(0, usd_python_path)\n",
    "\n",
    "from pxr import UsdGeom\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ad186",
   "metadata": {},
   "source": [
    "## Sampler testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b8a81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 4])\n",
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "from robofin.old.kinematics.numba import franka_arm_link_fk, franka_arm_visual_fk, franka_eef_visual_fk\n",
    "from robofin.old.kinematics.torch import franka_arm_link_fk as torch_franka_arm_link_fk\n",
    "from robofin.old.kinematics.torch import franka_arm_visual_fk as torch_franka_arm_visual_fk\n",
    "\n",
    "fk = robot.fk(robot.neutral_config)\n",
    "\n",
    "prismatic_joint = robot.auxiliary_joint_defaults[\"panda_finger_joint1\"]\n",
    "base_pose = np.eye(4)\n",
    "franka_fk = franka_arm_link_fk(robot.neutral_config, prismatic_joint, base_pose)\n",
    "franka_fk_dict = {\n",
    "    \"panda_link0\": franka_fk[0],\n",
    "    \"panda_link1\": franka_fk[1],\n",
    "    \"panda_link2\": franka_fk[2],\n",
    "    \"panda_link3\": franka_fk[3],\n",
    "    \"panda_link4\": franka_fk[4],\n",
    "    \"panda_link5\": franka_fk[5],\n",
    "    \"panda_link6\": franka_fk[6],\n",
    "    \"panda_link7\": franka_fk[7],\n",
    "    \"panda_link8\": franka_fk[8],\n",
    "    \"panda_hand\": franka_fk[9],\n",
    "    \"panda_grasptarget\": franka_fk[10],\n",
    "    \"right_gripper\": franka_fk[11],\n",
    "    \"panda_leftfinger\": franka_fk[12],\n",
    "    \"panda_rightfinger\": franka_fk[13],\n",
    "}\n",
    "\n",
    "torch_cfg = torch.Tensor(robot.neutral_config).unsqueeze(0)\n",
    "torch_fk = robot.fk_torch(torch_cfg)\n",
    "\n",
    "torch_base_pose = torch.Tensor(base_pose)\n",
    "torch_franka_fk = torch_franka_arm_link_fk(torch_cfg, prismatic_joint, torch_base_pose)\n",
    "torch_franka_fk_dict = {\n",
    "    \"panda_link0\": torch_franka_fk[:,0],\n",
    "    \"panda_link1\": torch_franka_fk[:,1],\n",
    "    \"panda_link2\": torch_franka_fk[:,2],\n",
    "    \"panda_link3\": torch_franka_fk[:,3],\n",
    "    \"panda_link4\": torch_franka_fk[:,4],\n",
    "    \"panda_link5\": torch_franka_fk[:,5],\n",
    "    \"panda_link6\": torch_franka_fk[:,6],\n",
    "    \"panda_link7\": torch_franka_fk[:,7],\n",
    "    \"panda_link8\": torch_franka_fk[:,8],\n",
    "    \"panda_hand\": torch_franka_fk[:,9],\n",
    "    \"panda_grasptarget\": torch_franka_fk[:,10],\n",
    "    \"right_gripper\": torch_franka_fk[:,11],\n",
    "    \"panda_leftfinger\": torch_franka_fk[:,12],\n",
    "    \"panda_rightfinger\": torch_franka_fk[:,13],\n",
    "}\n",
    "\n",
    "print(torch_fk[\"panda_hand\"].shape)\n",
    "print(torch_franka_fk_dict[\"panda_hand\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fbc5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robofin.samplers import NumpyRobotSampler, TorchRobotSampler\n",
    "from robofin.old.samplers import NumpyFrankaSampler, TorchFrankaSampler\n",
    "\n",
    "np_sampler = NumpyRobotSampler(robot)\n",
    "torch_sampler = TorchRobotSampler(robot)\n",
    "\n",
    "np_franka_sampler = NumpyFrankaSampler()\n",
    "torch_franka_sampler = TorchFrankaSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3250c5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Franka EE points shape: (128, 4)\n",
      "EE points shape: (128, 4)\n",
      "------------------------------\n",
      "Torch Franka EE points shape: torch.Size([1, 128, 4])\n",
      "Torch EE points shape: torch.Size([1, 128, 4])\n"
     ]
    }
   ],
   "source": [
    "franka_ee_pts = np_franka_sampler.sample_end_effector(fk[robot.tcp_link_name].squeeze(), prismatic_joint)\n",
    "ee_pts = np_sampler.sample_end_effector(fk[robot.tcp_link_name].squeeze())\n",
    "\n",
    "print(\"---\" * 10)\n",
    "print(f\"Franka EE points shape: {franka_ee_pts.shape}\")\n",
    "print(f\"EE points shape: {ee_pts.shape}\")\n",
    "\n",
    "torch_franka_ee_pts = torch_franka_sampler.sample_end_effector(torch_franka_fk_dict[robot.tcp_link_name], prismatic_joint)\n",
    "torch_ee_pts = torch_sampler.sample_end_effector(torch_fk[robot.tcp_link_name])\n",
    "\n",
    "print(\"---\" * 10)\n",
    "print(f\"Torch Franka EE points shape: {torch_franka_ee_pts.shape}\")\n",
    "print(f\"Torch EE points shape: {torch_ee_pts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f7d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_point(\n",
    "    point_cloud: np.ndarray, point: np.ndarray, tolerance: float = 1e-6\n",
    ") -> tuple[bool, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    exists, idx (bool, np.ndarray): Whether `point` exists in the point cloud\n",
    "        and the indices in the point cloud array where the point exists.\n",
    "    \"\"\"\n",
    "    mask = np.max(np.abs(point_cloud - point), axis=1) <= tolerance\n",
    "    exists = mask.any()\n",
    "    idx = np.flatnonzero(mask)\n",
    "    return exists, idx\n",
    "\n",
    "\n",
    "def compare_point_clouds(\n",
    "    pc1: np.ndarray, pc2: np.ndarray, abs_tol: float = 1e-7\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Return True if input point clouds are identical (within given tolerance)\n",
    "    \"\"\"\n",
    "    # return np.allclose(pc1, pc2, atol=abs_tol)\n",
    "    if np.allclose(pc1, pc2, atol=abs_tol):\n",
    "        return True\n",
    "\n",
    "    print(\"compare_point_clouds() returning False\")\n",
    "    print(\"Largest error:\", np.abs(pc1 - pc2).max())\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "862ad5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32meef_fk['panda_link8'] == lnk8_pose\u001b[0m\n",
      "------------------------------\n",
      "\u001b[36meef_fk['panda_link8'] EQUALS franka_eef_fk['panda_link8']\u001b[0m\n",
      "------------------------------\n",
      "\u001b[36meef_fk['panda_hand'] EQUALS franka_eef_fk['panda_hand']\u001b[0m\n",
      "------------------------------\n",
      "\u001b[36meef_fk['panda_grasptarget'] EQUALS franka_eef_fk['panda_grasptarget']\u001b[0m\n",
      "------------------------------\n",
      "\u001b[36meef_fk['right_gripper'] EQUALS franka_eef_fk['right_gripper']\u001b[0m\n",
      "------------------------------\n",
      "\u001b[36meef_fk['panda_leftfinger'] EQUALS franka_eef_fk['panda_leftfinger']\u001b[0m\n",
      "------------------------------\n",
      "\u001b[36meef_fk['panda_rightfinger'] EQUALS franka_eef_fk['panda_rightfinger']\u001b[0m\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from termcolor import cprint\n",
    "from robofin.samplers import get_points_on_robot_eef\n",
    "from robofin.old.kinematics.numba import get_points_on_franka_eef, eef_pose_to_link8, franka_eef_link_fk, franka_arm_visual_fk\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# frame = robot.tcp_link_name # right_gripper\n",
    "frame = \"panda_hand\"\n",
    "eef_pose = fk[frame].squeeze()\n",
    "# eef_pose = np.eye(4)\n",
    "eef_fk = robot.eef_fk(eef_pose, frame)\n",
    "\n",
    "lnk8_pose = eef_pose_to_link8(eef_pose, frame)\n",
    "franka_eef_fk_arr = franka_eef_link_fk(prismatic_joint, lnk8_pose)\n",
    "franka_eef_fk = {\n",
    "    \"panda_link8\": franka_eef_fk_arr[0],\n",
    "    \"panda_hand\": franka_eef_fk_arr[1],\n",
    "    \"panda_grasptarget\": franka_eef_fk_arr[2],\n",
    "    \"right_gripper\": franka_eef_fk_arr[3],\n",
    "    \"panda_leftfinger\": franka_eef_fk_arr[4],\n",
    "    \"panda_rightfinger\": franka_eef_fk_arr[5],\n",
    "}\n",
    "# visual_eef_fk = robot.eef_visual_fk(pose, frame, auxiliary_joint_values)\n",
    "\n",
    "if np.allclose(eef_fk[\"panda_link8\"], lnk8_pose):\n",
    "    cprint(\"eef_fk['panda_link8'] == lnk8_pose\", \"green\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "faulty_links = []\n",
    "for link_name in franka_eef_fk:\n",
    "    if np.allclose(eef_fk[link_name], franka_eef_fk[link_name]):\n",
    "        cprint(f\"eef_fk['{link_name}'] EQUALS franka_eef_fk['{link_name}']\", \"cyan\")\n",
    "    else:\n",
    "        cprint(f\"eef_fk['{link_name}'] DOES NOT EQUAL franka_eef_fk['{link_name}']\", \"red\")\n",
    "        faulty_links.append(link_name)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "\n",
    "eef_pts = get_points_on_robot_eef(robot, eef_pose, num_points=0, link_points=np_sampler.points, frame=frame)\n",
    "franka_eef_pts = get_points_on_franka_eef(eef_pose, prismatic_joint=0.04, sample=0, \n",
    "                                          panda_hand_points=np_franka_sampler.points[\"eef_panda_hand\"],\n",
    "                                          panda_leftfinger_points=np_franka_sampler.points[\"eef_panda_leftfinger\"],\n",
    "                                          panda_rightfinger_points=np_franka_sampler.points[\"eef_panda_rightfinger\"],\n",
    "                                          frame=frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c5c0396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mviz_server not running — starting…\u001b[0m\n",
      "\u001b[32mConnected to viz_server\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import viz_client\n",
    "\n",
    "urdf_path = \"/workspace/assets/panda/panda_spheres.urdf\"\n",
    "if not os.path.exists(urdf_path):\n",
    "    print(f\"❌ URDF not found at {urdf_path}\")\n",
    "    print(\"Please update the urdf_path variable in test_connect()\")\n",
    "    raise FileNotFoundError(f\"URDF not found at {urdf_path}\")\n",
    "\n",
    "viz_client.connect(urdf_path)\n",
    "viz_client.publish_joints(joints=robot.neutral_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6400d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_client.publish_ghost_end_effector(pose=fk[\"panda_hand\"], frame=\"panda_hand\", color=[0.8, 0.2, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84fe663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_client.clear_ghost_end_effector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a037936",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = robot.neutral_config.copy()\n",
    "config[0] = robot.neutral_config[0] + 1.0 \n",
    "viz_client.publish_ghost_robot(config, color=[0.5,0.6,0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30f76cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_client.clear_ghost_robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57c8a78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.018  3.752]\n",
      "[0.5  3.75]\n",
      "[-0.087  3.822]\n"
     ]
    }
   ],
   "source": [
    "from robofin.old.robot_constants import FrankaConstants, RealFrankaConstants\n",
    "print(FrankaConstants.JOINT_LIMITS[5])\n",
    "print(RealFrankaConstants.JOINT_LIMITS[5])\n",
    "print(robot.main_joint_limits[5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eae8f8b",
   "metadata": {},
   "source": [
    "## Dataloader testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "118b7334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from avoid_everything.data_loader import DataModule\n",
    "\n",
    "data_module_parameters = {\n",
    "    \"data_dir\": \"/workspace/datasets/ae_aristotle1_5mm_cubbies\",\n",
    "    \"train_trajectory_key\": \"global_solutions\",\n",
    "    \"val_trajectory_key\": \"global_solutions\",\n",
    "    \"num_obstacle_points\": 4096,\n",
    "    \"random_scale\": 0.015\n",
    "}\n",
    "shared_parameters = {\n",
    "    \"urdf_path\": \"assets/panda/panda.urdf\",\n",
    "    \"num_robot_points\": 2048,\n",
    "    \"num_target_points\": 128,\n",
    "    \"action_chunk_length\": 1\n",
    "}\n",
    "cfg = {\n",
    "    \"train_batch_size\": 10,\n",
    "    \"val_batch_size\": 10,\n",
    "    \"num_workers\": 4,\n",
    "}\n",
    "\n",
    "dm = DataModule(\n",
    "    train_batch_size=cfg[\"train_batch_size\"],\n",
    "    val_batch_size=cfg[\"val_batch_size\"],\n",
    "    num_workers=cfg[\"num_workers\"],\n",
    "    **data_module_parameters,\n",
    "    **shared_parameters,\n",
    ")\n",
    "\n",
    "dm.setup()\n",
    "\n",
    "dl = dm.train_dataloader()\n",
    "sample = dl.dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a893ff5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.dataset.__getitem__(3)[\"target_position\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f087bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def convert_to_numpy_f32(arr: np.ndarray | torch.Tensor) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a NumPy array or Torch tensor to a NumPy float32 array.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray or torch.Tensor\n",
    "        Input array to convert.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Converted array with dtype float32.\n",
    "    \"\"\"\n",
    "    if isinstance(arr, torch.Tensor):\n",
    "        np_arr: np.ndarray = arr.cpu().numpy()\n",
    "    elif isinstance(arr, np.ndarray):\n",
    "        np_arr: np.ndarray = arr\n",
    "    else:\n",
    "        raise TypeError(\"convert_to_numpy_f32: Input must be a NumPy array or Torch tensor\")\n",
    "    return np_arr.astype(np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuboid_dims = convert_to_numpy_f32(sample[\"cuboid_dims\"])\n",
    "cuboid_centers = convert_to_numpy_f32(sample[\"cuboid_centers\"])\n",
    "cuboid_quaternions = convert_to_numpy_f32(sample[\"cuboid_quats\"])\n",
    "for dims, center, quat in zip(cuboid_dims, cuboid_centers, cuboid_quaternions):\n",
    "    print(f\"Lengths: Dimensions: {len(dims)}, Center: {len(center)}, Quaternion: {len(quat)}\")\n",
    "\n",
    "cylinder_radii = convert_to_numpy_f32(sample[\"cylinder_radii\"])\n",
    "cylinder_heights = convert_to_numpy_f32(sample[\"cylinder_heights\"])\n",
    "cylinder_centers = convert_to_numpy_f32(sample[\"cylinder_centers\"])\n",
    "cylinder_quaternions = convert_to_numpy_f32(sample[\"cylinder_quats\"])\n",
    "for radius, height, center, quat in zip(cylinder_radii, cylinder_heights, cylinder_centers, cylinder_quaternions):\n",
    "    print(f\"Lengths: Radius: {len(radius)}, Height: {len(height)}, Center: {len(center)}, Quaternion: {len(quat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import viz_client\n",
    "\n",
    "urdf_path = \"/workspace/assets/panda/panda_spheres.urdf\"\n",
    "if not os.path.exists(urdf_path):\n",
    "    print(f\"❌ URDF not found at {urdf_path}\")\n",
    "    print(\"Please update the urdf_path variable in test_connect()\")\n",
    "    raise FileNotFoundError(f\"URDF not found at {urdf_path}\")\n",
    "\n",
    "viz_client.connect(urdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d165a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_client.publish_obstacles(cuboid_centers=cuboid_centers,\n",
    "                            cuboid_dims=cuboid_dims,\n",
    "                            cuboid_quaternions=cuboid_quaternions,\n",
    "                            cylinder_centers=cylinder_centers,\n",
    "                            cylinder_radii=cylinder_radii,\n",
    "                            cylinder_heights=cylinder_heights,\n",
    "                            cylinder_quaternions=cylinder_quaternions,\n",
    "                            color=[0.8, 0.5, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_client.clear_obstacles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3271b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_client.publish_joints(joints=robot.neutral_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3905d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
